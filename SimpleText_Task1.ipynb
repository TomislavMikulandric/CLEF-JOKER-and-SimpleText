{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "idrxuLGOdLLG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idrxuLGOdLLG",
    "outputId": "6ea6e1ee-0a03-4efa-b899-76066f1d139b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a8890-cac8-44f8-81d0-0fb0f4e12a09",
   "metadata": {
    "id": "446a8890-cac8-44f8-81d0-0fb0f4e12a09"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e976d6c-b03b-4de1-a4b6-13889ddfe099",
   "metadata": {
    "id": "1e976d6c-b03b-4de1-a4b6-13889ddfe099"
   },
   "outputs": [],
   "source": [
    "ES_URL = 'https://inex:qatc2011@guacamole.univ-avignon.fr/dblp1/_search'\n",
    "VECTOR_DB_URL = 'https://guacamole.univ-avignon.fr/stvir_test'\n",
    "HEADERS = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37a102-a7fd-48f9-af28-9c7087b9fa51",
   "metadata": {
    "id": "6e37a102-a7fd-48f9-af28-9c7087b9fa51"
   },
   "outputs": [],
   "source": [
    "# Function to query ElasticSearch\n",
    "def query_elasticsearch(query, size=100):\n",
    "    response = requests.get(f\"{ES_URL}?q={query}&size={size}\", auth=('inex', 'qatc2011'))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['hits']['hits']\n",
    "    else:\n",
    "        print(\"Failed to fetch data:\", response.status_code)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b62d1a-6a49-4023-8774-b029a899e0a6",
   "metadata": {
    "id": "53b62d1a-6a49-4023-8774-b029a899e0a6"
   },
   "outputs": [],
   "source": [
    "# Function to retrieve vector embeddings\n",
    "def get_vector_embeddings(phrase, length=100):\n",
    "    payload = {'corpus': 'abstract', 'phrase': phrase, 'length': length}\n",
    "    response = requests.get(VECTOR_DB_URL, params=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Failed to fetch embeddings:\", response.status_code)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26632ca-c361-424d-8f44-b6e1ce59e702",
   "metadata": {
    "id": "d26632ca-c361-424d-8f44-b6e1ce59e702"
   },
   "outputs": [],
   "source": [
    "# Function to calculate relevance scores\n",
    "def calculate_relevance(docs, query):\n",
    "    # Convert docs to a DataFrame\n",
    "    doc_texts = [doc['_source']['abstract'] for doc in docs if 'abstract' in doc['_source']]\n",
    "    df = pd.DataFrame(doc_texts, columns=['text'])\n",
    "\n",
    "    # Use TF-IDF to vectorize texts\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    doc_vectors = vectorizer.fit_transform(df['text'])\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cos_similarities = cosine_similarity(query_vector, doc_vectors).flatten()\n",
    "    return cos_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SbXHn7FTfxRw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbXHn7FTfxRw",
    "outputId": "2a5341eb-37ca-4901-aa40-f3f758fdba74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Flesch-Kincaid Grade Level score: 0.43190103626943016\n"
     ]
    }
   ],
   "source": [
    "def flesch_kincaid_grade_level(text):\n",
    "    # Constants for the formula\n",
    "    ASL = average_sentence_length(text)\n",
    "    ASW = average_syllables_per_word(text)\n",
    "\n",
    "    # Calculating the score\n",
    "    score = 0.39 * ASL + 11.8 * ASW - 15.59\n",
    "\n",
    "    # Normalize score to range from 0 to 1\n",
    "    normalized_score = normalize(score, min_score=0, max_score=25)  # 20+ is academic level texts\n",
    "\n",
    "    return normalized_score\n",
    "\n",
    "def normalize(value, min_score, max_score):\n",
    "    # Normalize value to range from 0 to 1\n",
    "    return (value - min_score) / (max_score - min_score) if max_score != min_score else 0.5\n",
    "\n",
    "def average_sentence_length(text):\n",
    "    sentences = text.split('.')\n",
    "    num_sentences = len(sentences)\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    return num_words / num_sentences\n",
    "\n",
    "def average_syllables_per_word(text):\n",
    "    words = text.split()\n",
    "    total_syllables = 0\n",
    "    for word in words:\n",
    "        total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables / len(words)\n",
    "\n",
    "def count_syllables(word):\n",
    "    # Rough estimation of syllable count in a word\n",
    "    count = 0\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    prev_char_was_vowel = False\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_was_vowel:\n",
    "                count += 1\n",
    "            prev_char_was_vowel = True\n",
    "        else:\n",
    "            prev_char_was_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "# Example usage\n",
    "text = \"Trials to introduce artificial intelligence (AI) in clinical settings have been done for several decades, but the movement toward such introduction remains slow. In the past, AI systems were mainly to support physicians. They were \\u201drule-based\\u201d and specifically designed to assist in diagnosis or to recommend drugs to be prescribed to patients. Current clinical medicine is not performed by a physician acting alone, but through cooperation between staff with various occupations. Kimura Information Technology Co., Ltd. (KIT, Japan) has built a system named \\u201dAI-Q\\u201d that works on the Japanese version of IBM\\u2019s Watson and with which it is possible to build arbitrary problem solving systems. AI-Q was made to serve a variety of purposes, and a system for pharmacists has been built for drug information. In this paper, we illustrate how practical applications of AI can be designed for use by medical staff other than physicians and discuss how the system can be extended to other fields. We converted an AI system previously used to support pharmacists into one for certified clinical engineers (CCE). The purpose of this paper is to give the background of the system for CCE and to evaluate it.\"\n",
    "print(\"Normalized Flesch-Kincaid Grade Level score:\", flesch_kincaid_grade_level(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261a313-05e5-45a4-8fc0-3a438d049cb3",
   "metadata": {
    "id": "f261a313-05e5-45a4-8fc0-3a438d049cb3"
   },
   "outputs": [],
   "source": [
    "# Function to format results\n",
    "def format_results(docs, scores, topic_id, query_id):\n",
    "    results = []\n",
    "    for doc, score in zip(docs, scores):\n",
    "        if score > 0.15:  # Threshold for including the document\n",
    "            result = {\n",
    "                \"run_id\": \"Tomislav&Rowan_Task1_TFIDF\",\n",
    "                \"manual\": 0,\n",
    "                \"topic_id\": topic_id,\n",
    "                \"query_id\": query_id,\n",
    "                \"doc_id\": doc['_id'],\n",
    "                \"rel_score\": round(score, 2),\n",
    "                \"comb_score\": round(flesch_kincaid_grade_level(doc['_source']['abstract']),2),\n",
    "                \"passage\": doc['_source']['abstract']\n",
    "            }\n",
    "            results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AngAfFxzd50F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AngAfFxzd50F",
    "outputId": "732d3f18-642c-4ccc-9d8e-05e1f103bce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task completed. Results stored in 'results.json'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    # Read queries from JSON file into a dataframe\n",
    "    queries = pd.read_json('/content/drive/MyDrive/BIP/SimpleText/task 1/task 1/topics_qrels/simpletext_2024_task1_queries.json')\n",
    "    queries = queries.head(5)\n",
    "\n",
    "    all_results = []\n",
    "    for index, query_row in queries.iterrows():\n",
    "        query_text = query_row['query_text']\n",
    "        topic_id = query_row['topic_id']\n",
    "        query_id = query_row['query_id']\n",
    "\n",
    "        docs = query_elasticsearch(query_text)\n",
    "        scores = calculate_relevance(docs, query_text)\n",
    "        results = format_results(docs, scores,topic_id, query_id)\n",
    "        all_results.extend(results)\n",
    "\n",
    "    # Output results to a JSON file\n",
    "    with open('results.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "\n",
    "    print(\"Task completed. Results stored in 'results.json'.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ae9ee-4d97-4532-adf9-21feefe2c87f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c85ae9ee-4d97-4532-adf9-21feefe2c87f",
    "outputId": "f5590957-5525-4cdb-99f0-dcc92c62f9d6"
   },
   "outputs": [],
   "source": [
    "json_file_path = \"results.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    results = json.load(file)\n",
    "\n",
    "# Display the contents of the JSON file\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Fr0cuhkCQdi",
   "metadata": {
    "id": "-Fr0cuhkCQdi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
